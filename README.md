Use DQN to train the cart to reach the goal.

For RL, it is not successful when an obstacle is added. Maybe the reward or the hyper parameters need tuning.

For the environment, I doesn't use gym, just code a simple environment based on the polytope library.

## Update: simplification
Consider the jetbot in a circle, and check whether the circle covers the obstacles.

